{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification_main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoGranja/CIFAR10_ImageClassification/blob/master/image_classification_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fug7eGzTzLbg"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "is_colab = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PycgYA0ppQa"
      },
      "source": [
        "\n",
        "# **Colab Preparation** \n",
        "Before handling the project, we need to install keras and pip packages. I also share my google drive to simplify the connection with my google drive account.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j5egONdppQb",
        "outputId": "bcd29bed-9846-4589-f733-1087795e150e"
      },
      "source": [
        "if is_colab:\n",
        "    #Package Installation and share Google Drive\n",
        "    !pip install --upgrade pip\n",
        "    !pip install --upgrade keras\n",
        "    !pip install keras-resnet\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n",
            "Requirement already satisfied: keras-resnet in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.2.4->keras-resnet) (1.5.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NToyjnZ4Uc2k"
      },
      "source": [
        " # **Configuration and imports**\n",
        "\n",
        "First thing I do is to import all modules we need for this project. I also use some configuration parameters to be used through the project\n",
        "\n",
        "In this project I will be making use of the Keras library for creating our model and training it. I will also use Matplotlib and Seaborn for visualizing our dataset to gain a better understanding of the images we are going to be handling. Another important library to handle image data is Opencv.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk78b8REzLbl"
      },
      "source": [
        "# Generic Imports\n",
        "import time\n",
        "import gc\n",
        "import logging, os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "import pickle\n",
        "from math import ceil\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "\n",
        "# data processing and visualization library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# image procesing library\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "import cv2 \n",
        "\n",
        "# tensorflow and keras for CNN model\n",
        "import tensorflow as tf\n",
        "logging.disable(logging.WARNING)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import keras\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from keras.optimizers import RMSprop, Adam, SGD\n",
        "from keras import backend as K\n",
        "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
        "from keras.datasets import cifar10\n",
        "#from keras.utils import multi_gpu_model\n",
        "from keras.preprocessing.image import Iterator, load_img, img_to_array\n",
        "\n",
        "if is_colab:\n",
        "    from google.colab import files\n",
        "    sys.path.append('/content/drive/MyDrive/colab/CIFAR10_Image_Classification')\n",
        "    os.chdir('/content/drive/MyDrive/colab/CIFAR10_Image_Classification')\n",
        "    \n",
        "#------------------------------  Set some configuration parameters -----------------------------------#\n",
        "args = {}\n",
        "args['seed'] = 42\n",
        "args['data_augmentation'] = False\n",
        "\n",
        "#training arguments\n",
        "args['batch_size'] = 32\n",
        "args['epochs'] = 10\n",
        "args['validation_split'] = 0.2\n",
        "\n",
        "#model arguments\n",
        "args['networks'] = ['leNet', 'VGG16', 'VGG19']\n",
        "#args['networks'] = ['VGG16']\n",
        "\n",
        "#optimizer arguments\n",
        "args['optimizer'] = 'adam'\n",
        "args['learning_rate'] = 0.001\n",
        "args['decay'] = 0.0001\n",
        "args['loss'] = 'sparse_categorical_crossentropy'\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjI2CcCKppQe"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "In this project I will use the CIFAR10 dataset which is comprised of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class labels and their standard associated integer values are listed below. More information is available on [CIFAR homepage](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "<ul>\n",
        "<li> 0: airplane </li>\n",
        "<li> 1: automobile </li>\n",
        "<li> 2: bird </li>\n",
        "<li> 3: cat </li>\n",
        "<li> 4: deer </li>\n",
        "<li> 5: dog </li>\n",
        "<li> 6: frog </li>\n",
        "<li> 7: horse </li>\n",
        "<li> 8: ship </li>\n",
        "<li> 9: truck </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32RfKAg6ppQf"
      },
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as data:\n",
        "        dataset = pickle.load(data)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T8_V1PqppQg",
        "outputId": "ba6bf520-e8f2-4bcd-d5d1-40134bb101f8"
      },
      "source": [
        "#------------------------------  Load dataset using keras.dataset API -----------------------------------#\n",
        "download_dataset = False\n",
        "if download_dataset:\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    dataset = {}\n",
        "    dataset['x_train'], dataset['y_train'], dataset['x_test'], dataset['y_test'] = x_train, y_train, x_test, y_test\n",
        "    with open('dataset/cifar10.pickle', 'wb') as output:\n",
        "        pickle.dump(dataset, output)\n",
        "else:\n",
        "    dataset = unpickle('dataset/cifar10.pickle')\n",
        "    #(x_train, y_train), (x_test, y_test) = (dataset['x_train'][:5000], dataset['y_train'][:5000]), (dataset['x_test'][:1000], dataset['y_test'][:1000])\n",
        "    (x_train, y_train), (x_test, y_test) = (dataset['x_train'], dataset['y_train']), (dataset['x_test'], dataset['y_test'])\n",
        "\n",
        "\n",
        "#Check train and test dataset shape\n",
        "print(\"Train dataset: x={} y={}\".format(x_train.shape, y_train.shape))\n",
        "print(\"Test dataset: x={} y={}\".format(x_test.shape, y_test.shape))\n",
        "\n",
        "#Check number of classes and image shape\n",
        "print(\"Image data shape =\", x_train.shape[1:])\n",
        "nr_classes = len(np.unique(y_train))\n",
        "print(\"Number of classes =\", nr_classes )\n",
        "\n",
        "#Class dictionary with classes names\n",
        "class_names = {}\n",
        "class_names[0] = 'airplane'\n",
        "class_names[1] = 'automobile'\n",
        "class_names[2] = 'bird'\n",
        "class_names[3] = 'cat'\n",
        "class_names[4] = 'deer'\n",
        "class_names[5] = 'dog'\n",
        "class_names[6] = 'frog'\n",
        "class_names[7] = 'horse'\n",
        "class_names[8] = 'ship'\n",
        "class_names[9] = 'truck'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset: x=(50000, 32, 32, 3) y=(50000, 1)\n",
            "Test dataset: x=(10000, 32, 32, 3) y=(10000, 1)\n",
            "Image data shape = (32, 32, 3)\n",
            "Number of classes = 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "2v20CtzuppQj",
        "outputId": "14b1347d-e55c-4069-e498-8ec4ddfe7eee"
      },
      "source": [
        "#------------------------------ Plot random images and respective labels -----------------------------------#\n",
        "n_images = 5\n",
        "fig, axs = plt.subplots(1, n_images, figsize=(12, 12))\n",
        "fig.tight_layout(pad=1.0)\n",
        "   \n",
        "for i in range(n_images):\n",
        "    index = random.randint(0, len(x_train))\n",
        "    image = x_train[index].squeeze()\n",
        "\n",
        "    axs[i].imshow(image)\n",
        "    axs[i].set_title(\"Label = {0}\".format(class_names[int(y_train[index])]))\n",
        "    axs[i].get_xaxis().set_visible(False)\n",
        "    axs[i].get_yaxis().set_visible(False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLijVktappQk"
      },
      "source": [
        "Analyzing the images it is clear that the images resolution is small, actually 32x32 has few pixels and therefore can be a challenge for a model to classify correctly the object. Furthermore all image has the same size so it is not required to resize the input images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9i_voo8zLbs"
      },
      "source": [
        "# **Pre-processing the train and test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZGByJN1ppQo",
        "outputId": "512c242c-4dc5-47a7-aa9c-1fa5a44daeb0"
      },
      "source": [
        "from aug.functional import transform_image, normalize_image\n",
        "x_train_ = x_train\n",
        "y_train_ = y_train\n",
        "\n",
        "#------------------------------ Random data augmentation -----------------------------------#\n",
        "if args['data_augmentation']:\n",
        "    data_aug_samples = 2\n",
        "    for i in range(data_aug_samples):\n",
        "        x_train_ = np.vstack((x_train_,transform_image(x_train)))\n",
        "        y_train_ = np.vstack((y_train_,y_train))\n",
        "\n",
        "    #Check train dataset shape\n",
        "    print(\"Train dataset: x={} y={}\".format(x_train_.shape, y_train_.shape))\n",
        "\n",
        "#------------------------------ Normalization of images dataset -----------------------------------#\n",
        "x_test_norm = normalize_image(x_test)\n",
        "x_train_norm = normalize_image(x_train_)\n",
        "\n",
        "#------------------------------ Remove old varibles -----------------------------------#\n",
        "del x_test, x_train, y_train, x_train_\n",
        "x_train, y_train, x_test = x_train_norm, y_train_, x_test_norm\n",
        "del x_train_norm, y_train_, x_test_norm\n",
        "gc.collect\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function gc.collect>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QCnufRUl-Z5"
      },
      "source": [
        "# **Optimizer**\n",
        "\n",
        "Before training it is necessary to choose an optimizer which will be responsible to adjust model parameters in order to reduce the loss funcion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INAQZOJSphOA"
      },
      "source": [
        "#------------------------------ Define an optimizer -----------------------------------#\n",
        "if 'optimizer' in args:\n",
        "    if args['optimizer'] == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate=args['learning_rate'], decay=float(args['decay']))\n",
        "    elif args['optimizer'] == 'adam':\n",
        "        optimizer = Adam(learning_rate=args['learning_rate'], decay=float(args['decay']))\n",
        "    elif args['optimizer'] == 'amsgrad':\n",
        "        optimizer = Adam(learning_rate=args['learning_rate'], decay=float(args['decay']), amsgrad=True)\n",
        "    elif args['optimizer'] == 'sgd':\n",
        "        optimizer = SGD(learning_rate=args['learning_rate'], momentum=0.9, nesterov=True, decay=float(args['decay']))\n",
        "else:\n",
        "    optimizer = RMSprop(learning_rate=args['learning_rate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWLJo5_bppQs"
      },
      "source": [
        "# **Model**\n",
        "\n",
        "In this project, I will first use a simple CNN model following the LeNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd5VM-R-Su0_",
        "outputId": "96665922-7b6a-4426-d849-c9d961d22a58"
      },
      "source": [
        "from models.model_factory import make_model\n",
        "\n",
        "models = []\n",
        "for network in args['networks']:\n",
        "  #------------------------------ Make the model -----------------------------------#\n",
        "  if 'multi_gpu' in args:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "      print(\n",
        "        '\\n\\nThis error most likely means that this notebook is not '\n",
        "        'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "        'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "      raise SystemError('GPU device not found')\n",
        "\n",
        "      with K.tf.device(\"/cpu:0\"):\n",
        "          model = make_model(network, x_train.shape[1:])\n",
        "  else:\n",
        "      model = make_model(network, x_train.shape[1:], nr_classes)\n",
        "      \n",
        "  if 'weights' not in args:\n",
        "      print('No weights passed, training from scratch')\n",
        "  else:\n",
        "      weights_path = args['weights']\n",
        "      print('Loading weights from {}'.format(weights_path))\n",
        "      model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "  #------------------------------ Compile the model -----------------------------------#\n",
        "  model.compile(loss=args['loss'], optimizer=optimizer, metrics=['accuracy']) \n",
        "  model.summary()\n",
        "  models.append(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No weights passed, training from scratch\n",
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 16)        1216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 32)        12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              257000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               100100    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 759,678\n",
            "Trainable params: 759,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "No weights passed, training from scratch\n",
            "Model: \"VGG16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper (ModuleWrappe (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 14,719,818\n",
            "Trainable params: 14,719,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "No weights passed, training from scratch\n",
            "Model: \"VGG19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper_1 (ModuleWrap (None, 1, 1, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 20,029,514\n",
            "Trainable params: 20,029,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSADHpegzLb-"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSWGGh32Svnu",
        "outputId": "811c20e2-dfec-47bd-9f20-fdd6d0790011"
      },
      "source": [
        "args['models_dir'] = 'nn_models_checkpoints'\n",
        "\n",
        "histories = []\n",
        "for model in models:\n",
        "  print(\"Training model {}\".format(model.name))\n",
        "  #------------------------------ Model check points -----------------------------------#\n",
        "  best_model_file = '{}/best_{}.h5'.format(args['models_dir'], model.name)\n",
        "  last_model_file = '{}/last_{}.h5'.format(args['models_dir'], model.name)\n",
        "\n",
        "  #------------------------------ Callbacks -----------------------------------#\n",
        "  callbacks = [\n",
        "          # Callback to reduce the learning rate once the plateau has been reached:\n",
        "          ReduceLROnPlateau(\n",
        "              monitor='val_loss',\n",
        "              factor=1/3,\n",
        "              patience=2,\n",
        "              mode='auto',\n",
        "              verbose=1,\n",
        "              cooldown=0,\n",
        "              min_lr=1e-8\n",
        "          ),\n",
        "          # Callback to stop the training once no more improvements are recorded:\n",
        "          EarlyStopping(\n",
        "              min_delta=0.001,\n",
        "              verbose=1,\n",
        "              patience=5,\n",
        "              mode='auto',\n",
        "              restore_best_weights=True\n",
        "          ),\n",
        "          # Callback to log the graph, losses and metrics into TensorBoard:\n",
        "          TensorBoard(log_dir=\"logs/{}\".format(model.name)\n",
        "          ),\n",
        "          # Callback to save the best and last model specifying the epoch and val-loss in the filename:\n",
        "          ModelCheckpoint(filepath=last_model_file, \n",
        "              monitor='val_loss',\n",
        "              verbose=1,\n",
        "              mode='min',\n",
        "              save_freq='epoch',\n",
        "              save_best_only=False,\n",
        "              save_weights_only=True\n",
        "          ),\n",
        "          ModelCheckpoint(filepath=best_model_file, \n",
        "              monitor='val_loss',\n",
        "              verbose=1,\n",
        "              mode='min',\n",
        "              save_freq='epoch',\n",
        "              save_best_only=True,\n",
        "              save_weights_only=True)\n",
        "      ]\n",
        "\n",
        "  #------------------------------ Model Fit -----------------------------------#\n",
        "  history = model.fit(x_train, y_train,\n",
        "                      validation_split=args['validation_split'],\n",
        "                      epochs=args['epochs'], \n",
        "                      batch_size=args['batch_size'], \n",
        "                      verbose=1,\n",
        "                      callbacks=callbacks)\n",
        "  histories.append(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model LeNet\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 34s 15ms/step - loss: 1.7944 - accuracy: 0.3224 - val_loss: 1.2198 - val_accuracy: 0.5678\n",
            "\n",
            "Epoch 00001: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.21982, saving model to nn_models_checkpoints/best_LeNet.h5\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.1746 - accuracy: 0.5747 - val_loss: 1.0248 - val_accuracy: 0.6381\n",
            "\n",
            "Epoch 00002: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.21982 to 1.02478, saving model to nn_models_checkpoints/best_LeNet.h5\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.9410 - accuracy: 0.6619 - val_loss: 0.9147 - val_accuracy: 0.6733\n",
            "\n",
            "Epoch 00003: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.02478 to 0.91472, saving model to nn_models_checkpoints/best_LeNet.h5\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.7873 - accuracy: 0.7254 - val_loss: 0.9193 - val_accuracy: 0.6816\n",
            "\n",
            "Epoch 00004: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.91472\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6656 - accuracy: 0.7671 - val_loss: 0.8665 - val_accuracy: 0.6981\n",
            "\n",
            "Epoch 00005: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.91472 to 0.86653, saving model to nn_models_checkpoints/best_LeNet.h5\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5524 - accuracy: 0.8047 - val_loss: 0.8965 - val_accuracy: 0.6951\n",
            "\n",
            "Epoch 00006: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.86653\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4555 - accuracy: 0.8365 - val_loss: 0.8925 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0003333333491658171.\n",
            "\n",
            "Epoch 00007: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.86653\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.2862 - accuracy: 0.9012 - val_loss: 1.0380 - val_accuracy: 0.7239\n",
            "\n",
            "Epoch 00008: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.86653\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 0.1896 - accuracy: 0.9364 - val_loss: 1.1261 - val_accuracy: 0.7222\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00011111111962236464.\n",
            "\n",
            "Epoch 00009: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.86653\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 0.1202 - accuracy: 0.9634 - val_loss: 1.2719 - val_accuracy: 0.7246\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00010: saving model to nn_models_checkpoints/last_LeNet.h5\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.86653\n",
            "Epoch 00010: early stopping\n",
            "Training model VGG16\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 83s 64ms/step - loss: 1.1695 - accuracy: 0.5803 - val_loss: 0.6020 - val_accuracy: 0.7998\n",
            "\n",
            "Epoch 00001: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.60204, saving model to nn_models_checkpoints/best_VGG16.h5\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 84s 67ms/step - loss: 0.4753 - accuracy: 0.8384 - val_loss: 0.4704 - val_accuracy: 0.8376\n",
            "\n",
            "Epoch 00002: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.60204 to 0.47043, saving model to nn_models_checkpoints/best_VGG16.h5\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.3173 - accuracy: 0.8914 - val_loss: 0.4445 - val_accuracy: 0.8490\n",
            "\n",
            "Epoch 00003: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.47043 to 0.44450, saving model to nn_models_checkpoints/best_VGG16.h5\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.2019 - accuracy: 0.9312 - val_loss: 0.4677 - val_accuracy: 0.8529\n",
            "\n",
            "Epoch 00004: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.44450\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.1169 - accuracy: 0.9622 - val_loss: 0.5440 - val_accuracy: 0.8495\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.703703987412155e-05.\n",
            "\n",
            "Epoch 00005: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.44450\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 84s 67ms/step - loss: 0.0473 - accuracy: 0.9863 - val_loss: 0.5593 - val_accuracy: 0.8655\n",
            "\n",
            "Epoch 00006: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.44450\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.6369 - val_accuracy: 0.8667\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.2345679958040515e-05.\n",
            "\n",
            "Epoch 00007: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.44450\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 84s 67ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.6752 - val_accuracy: 0.8688\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00008: saving model to nn_models_checkpoints/last_VGG16.h5\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.44450\n",
            "Epoch 00008: early stopping\n",
            "Training model VGG19\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 105s 83ms/step - loss: 1.1362 - accuracy: 0.5962 - val_loss: 0.7056 - val_accuracy: 0.7523\n",
            "\n",
            "Epoch 00001: saving model to nn_models_checkpoints/last_VGG19.h5\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.70563, saving model to nn_models_checkpoints/best_VGG19.h5\n",
            "Epoch 2/10\n",
            " 731/1250 [================>.............] - ETA: 38s - loss: 0.6508 - accuracy: 0.7770"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI4rNBwYgXwv"
      },
      "source": [
        "# **Visualise Model Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tUF9-UtppQx"
      },
      "source": [
        "#------------------------------ Plot diagnostic learning curves -----------------------------------#\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    # save plot to file\n",
        "    filename = \"accuracy\"\n",
        "    plt.savefig(filename + '_plot.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "  \n",
        "for history in histories:\n",
        "  summarize_diagnostics(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg9NFaPNzLcH"
      },
      "source": [
        "# **Evaluation**\n",
        "\n",
        "Evaluate the model over the test dataset. We will use the last model weights and predict the class for some test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HGuxPkippQy"
      },
      "source": [
        "del models\n",
        "gc.collect\n",
        "\n",
        "print( models)\n",
        "#------------------------------ Predict on some test images -----------------------------------#\n",
        "for network in args['networks']:\n",
        "  #Load last model parameters\n",
        "  last_model_file = '{}/last_{}.h5'.format(args['models_dir'], network)\n",
        "  print(last_model_file)\n",
        "  model.load_weights(last_model_file, by_name=True)\n",
        "\n",
        "  #Try out the model on an image from the test data:\n",
        "  n_images = 5\n",
        "  fig, axs = plt.subplots(1, n_images, figsize=(12, 12))\n",
        "  fig.tight_layout(pad=1.0)\n",
        "\n",
        "          \n",
        "  # View the images\n",
        "  for i in range(n_images):\n",
        "      index = random.randint(0, len(x_test))\n",
        "      image = x_test[index].squeeze()\n",
        "      true_index = int(y_test[index])\n",
        "\n",
        "      prediction_scores = model.predict(np.expand_dims(image, axis=0))\n",
        "      predicted_index = np.argmax(prediction_scores)\n",
        "      \n",
        "      image = np.add(image*128,128).astype(int)\n",
        "      axs[i].imshow(image)\n",
        "      axs[i].set_title(\"True Label = {0}, \\n Predicted label = {1}\".format(class_names[true_index], class_names[predicted_index]))\n",
        "      axs[i].get_xaxis().set_visible(False)\n",
        "      axs[i].get_yaxis().set_visible(False)\n",
        "\n",
        "\n",
        "  #------------------------------ Evaluate model on testing dataset -----------------------------------#\n",
        "  _, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(\"Testing Accuracy = {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eAd5vkkppQ0"
      },
      "source": [
        "#------------------------------ Evaluate and compare the several models on testing dataset -----------------------------------#\n",
        "for network in args['networks']:\n",
        "  #Load last model parameters\n",
        "  last_model_file = '{}/last_{}.h5'.format(args['models_dir'], network)\n",
        "  print(last_model_file)\n",
        "  model.load_weights(last_model_file, by_name=True)\n",
        "\n",
        "  #------------------------------ Evaluate model on testing dataset -----------------------------------#\n",
        "  accuracies = {}\n",
        "  _, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(\"Testing Accuracy = {}\".format(acc))  \n",
        "  accuracies['netwokr'] = acc\n",
        "\n",
        "\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "for model_name in accuracies:\n",
        "  plt.plot(epochs_range, accuracies[model_name], label=model_name)\n",
        "  plt.legend(loc='lower right')\n",
        "plt.title('Testing Accuracy')\n",
        "\n",
        "\n",
        "# save plot to file\n",
        "filename = \"test_accuracy\"\n",
        "plt.savefig(filename + '_plot.png')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfrD3I1TYU8L"
      },
      "source": [
        "**Future Work**\n",
        "\n",
        "In this project I applied transfer learning to several pre-trained models and train added fully connected layer parameters with the new dataset. However I could fine-tune "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPWtblE5YWzW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}